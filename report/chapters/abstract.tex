\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
This master's thesis expands on work previously done at the UCL's autonomous drone project to allow three dimensional simultaneous localization and mapping by a low-cost quadcopter. In GPS-denied environments, drones have to rely on their on-board sensors to localize themselves. We decided to use the drone's front camera to build a map of the environment and to localize the drone within that map. We take a keyframe-based approach, building a map from a small set of snapshots of the drone's camera image, and comparing keypoints in these images. We show that our method is able to build an accurate map using the drone's camera output, and a measurement of the drone's altitude (such as one from an ultrasonic sensor).